{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d5751ce",
   "metadata": {},
   "source": [
    "# Make Data Frame and Save Out Cohort Files for ModelArray\n",
    "## This happens before running the GAMs\n",
    "## Make sure by this time only subjects you want to include in the FBA are in the FBA derivatives directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f51675d-e6eb-4b57-9e73-1bf835b2cd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pingouin\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import os\n",
    "import os.path\n",
    "import statistics\n",
    "\n",
    "# CHANGE THIS VARIABLE TO REFLECT WHERE YOUR HBN BIDS DATA LIVE ()\n",
    "bids_dir = '/om4/group/gablab/data/hbn_bids/' # Path should end with a '/'\n",
    "\n",
    "# THESE VARIABLES SHOULD NOT CHANGE IF THE ANALYSIS WAS RUN ACCORDING TO INSTRUCTIONS\n",
    "code_dir = bids_dir+'code/'\n",
    "derivatives_dir = bids_dir+'derivatives/'\n",
    "pod2_dir = derivatives_dir+'qsiprep/'\n",
    "fba_dir = derivatives_dir+'fba/'\n",
    "freesurfer_dir = derivatives_dir+'freesurfer/'\n",
    "out_variable_dir = os.getcwd()+'/output_variables/'\n",
    "\n",
    "# LOAD THE PHENOTYPIC DATA\n",
    "HBN_query = pd.read_csv(code_dir+'HBN_query.csv') # This should point to the phenotypic file downloaded from LORIS\n",
    "participants_tsv = pd.read_csv(pod2_dir+'participants.tsv',delimiter='\\t')\n",
    "\n",
    "# GET SUBJECTS WITH PHENOTYPIC DATA\n",
    "query_subs = ['sub-'+name[:-11] for name in HBN_query['Identifiers']]\n",
    "pod2_subs = list(participants_tsv['subject_id'])\n",
    "pod2_subs.sort()\n",
    "\n",
    "# GET SUBJECTS INCLUDED IN FBA\n",
    "subs_final= np.asarray([s.split('/')[-1] for s in glob.glob(fba_dir+'sub*')])\n",
    "subs_final.sort()\n",
    "\n",
    "# GET INDEXES OF SUBJECTS IN PHENOTYPIC FILES\n",
    "pod2_inds_final = np.asarray([pod2_subs.index(sub) for sub in subs_final])\n",
    "query_inds_final = np.asarray([query_subs.index(sub) for sub in subs_final])\n",
    "\n",
    "# TRACTS TO ANALYZE\n",
    "tracts = [] # If you want to add average tract stats to the data frame, add tract names below using TractSeg naming conventions\n",
    "#tracts = ['AF_left','AF_right','SLF_I_left','SLF_I_right']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537643f3",
   "metadata": {},
   "source": [
    "### Extract phenotypes for subjects passing QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d282aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = subs_final\n",
    "n = np.size(subs) # number of subjects\n",
    "site = participants_tsv['scan_site_id'][pod2_inds_final]\n",
    "sex = ['M' if sex_sub==0.0 else 'F' for sex_sub in np.asarray(HBN_query['Basic_Demos,Sex'][query_inds_final])]\n",
    "age = np.asarray(HBN_query['Basic_Demos,Age'][query_inds_final])\n",
    "ehi = np.asarray(HBN_query['EHQ,EHQ_Total'][query_inds_final]).astype(float)\n",
    "# Convert EHI scores to handedness\n",
    "hand = []\n",
    "for h in ehi:\n",
    "    if h < -40: hand.append('L')\n",
    "    elif h >= -40 and h <= 40: hand.append('A')\n",
    "    elif h > 40: hand.append('R')\n",
    "\n",
    "# Reading Measures (Standardized)\n",
    "towre = np.asarray(HBN_query['TOWRE,TOWRE_Total_Scaled'][query_inds_final]).astype(float)\n",
    "swe = np.asarray(HBN_query['TOWRE,TOWRE_SWE_Scaled'][query_inds_final]).astype(float)\n",
    "pde = np.asarray(HBN_query['TOWRE,TOWRE_PDE_Scaled'][query_inds_final]).astype(float)\n",
    "# Raw Reading Measures\n",
    "swe_r = np.asarray(HBN_query['TOWRE,TOWRE_SWE_Raw'][query_inds_final]).astype(float)\n",
    "pde_r = np.asarray(HBN_query['TOWRE,TOWRE_PDE_Raw'][query_inds_final]).astype(float)\n",
    "towre_r = swe_r + pde_r\n",
    "\n",
    "# Make RD and TR groups\n",
    "groups=[]\n",
    "for index in range(n):\n",
    "    ind_query = query_inds_final[index]\n",
    "    # Get diagnostic information\n",
    "    dxs = [HBN_query[key][ind_query] for key in HBN_query.keys() if 'DX' in key]\n",
    "    # Check if participant was diagnosed with RD\n",
    "    dx_check = [('Impairment in Reading' in dx) for dx in dxs if type(dx)==str]\n",
    "    # Implement score and diagnosis classification\n",
    "    if sum(dx_check)>0 and swe[index]<=85 and pde[index]<=85:\n",
    "        groups.append('RD')\n",
    "    elif sum(dx_check)==0 and swe[index]>=90 and pde[index]>90:\n",
    "        groups.append('TR')\n",
    "    else:\n",
    "        groups.append('OTHER')\n",
    "        \n",
    "# These contain NaNs and have to be dealt with differently\n",
    "ses = np.asarray(pd.to_numeric(HBN_query['Barratt,Barratt_Total_Edu'][query_inds_final],errors='coerce'))\n",
    "wisc_vsi = np.asarray(pd.to_numeric(HBN_query['WISC,WISC_VSI'][query_inds_final],errors='coerce')) # Visual Spatial Index\n",
    "wisc_vci = np.asarray(pd.to_numeric(HBN_query['WISC,WISC_VCI'][query_inds_final],errors='coerce')) # Verbal Comprehension Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07716fe4",
   "metadata": {},
   "source": [
    "### Extract intracranial volumes, mean FD, and globally averaged fixel metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39943290",
   "metadata": {},
   "outputs": [],
   "source": [
    "icvs = []\n",
    "gfds = []\n",
    "gfcs = []\n",
    "gfdcs = []\n",
    "motions = []\n",
    "neighbor_corrs = []\n",
    "\n",
    "for sub in subs_final:\n",
    "    \n",
    "    # ICV comes from FreeSurfer\n",
    "    fs_stats_path = freesurfer_dir+sub+'/stats/aseg.stats'\n",
    "    with open(fs_stats_path) as f:\n",
    "        lines = f.readlines()\n",
    "    # Extract the brain volume and add to list\n",
    "    icv_text = lines[34]\n",
    "    icv = float((icv_text.split(',')[-2]))\n",
    "    icvs.append(icv)\n",
    "\n",
    "    # Get quality measures (motion and neighbor correlation)     \n",
    "    qc_path = glob.glob(pod2_dir+'/'+sub+'/ses-*/dwi/'+sub+'_ses-*ImageQC_dwi.csv')[0]\n",
    "    qc = pd.read_csv(qc_path)\n",
    "    motions.append(qc['mean_fd'][0])\n",
    "    neighbor_corrs.append(qc['raw_neighbor_corr'][0])\n",
    "    \n",
    "    # Globally averaged fixel stats below\n",
    "    gfd_path = fba_dir+'template/fixel_stats/gfd/'+sub+'_gfd.txt'\n",
    "    with open(gfd_path) as f:\n",
    "        lines = f.readlines()\n",
    "    gfd = float(lines[0].strip())\n",
    "    gfds.append(gfd)\n",
    "    \n",
    "    gfc_path = fba_dir+'template/fixel_stats/glog_fc/'+sub+'_glog_fc.txt'\n",
    "    with open(gfc_path) as f:\n",
    "        lines = f.readlines()\n",
    "    gfc = float(lines[0].strip())\n",
    "    gfcs.append(gfc)\n",
    "    \n",
    "    gfdc_path = fba_dir+'template/fixel_stats/gfdc/'+sub+'_gfdc.txt'\n",
    "    with open(gfdc_path) as f:\n",
    "        lines = f.readlines()\n",
    "    gfdc = float(lines[0].strip())\n",
    "    gfdcs.append(gfdc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfd71d7",
   "metadata": {},
   "source": [
    "### Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c67a53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataframe\n",
    "df = pd.DataFrame()\n",
    "df['subject_id'] = subs\n",
    "df['GROUP'] = groups\n",
    "df['AGE'] = age\n",
    "df['SEX'] = sex\n",
    "df['EHI'] = ehi\n",
    "df['HAND'] = hand\n",
    "df['TOWRE'] = towre\n",
    "df['SWE'] = swe\n",
    "df['PDE'] = pde\n",
    "df['SWE_RAW'] = swe_r\n",
    "df['PDE_RAW'] = pde_r\n",
    "df['TOWRE_RAW'] = towre_r\n",
    "df['SES'] = ses\n",
    "df['WISC_VSI']=wisc_vsi\n",
    "df['WISC_VCI']=wisc_vci\n",
    "df['ICV'] = icvs\n",
    "df['logICV'] = np.log(icvs)\n",
    "df['gFD'] = gfds\n",
    "df['gFC'] = gfcs\n",
    "df['gFDC'] = gfdcs\n",
    "df['MOTION'] = motions\n",
    "df['N_CORR'] = neighbor_corrs\n",
    "df['SITE'] = np.asarray(site)\n",
    "# Add tract averages if of interest\n",
    "for tract in tracts:\n",
    "    df[tract+'_fd'] = [float(open(fba_dir+'template/tractstats/fd/'+sub+'/'+tract+'.txt').readlines()[0].strip()) for sub in subs]\n",
    "    df[tract+'_fc'] = [float(open(fba_dir+'template/tractstats/fc/'+sub+'/'+tract+'.txt').readlines()[0].strip()) for sub in subs]\n",
    "    df[tract+'_fc'] = [float(open(fba_dir+'template/tractstats/fdc/'+sub+'/'+tract+'.txt').readlines()[0].strip()) for sub in subs]\n",
    "# Save out dataframe\n",
    "df.to_pickle(out_variable_dir+'df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89a2581-8670-4e4a-b919-7381a212199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be25ddbc-0a4a-413d-9947-4864bd782ec7",
   "metadata": {},
   "source": [
    "## Make cohort files for ModelArray analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0f6dba-c847-4a37-b580-22e744b1876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make output folders\n",
    "if os.path.isdir(fba_dir+'template/modelarray_inputs') == False:\n",
    "    os.makedirs(fba_dir+'template/modelarray_inputs')\n",
    "if os.path.isdir(fba_dir+'template/modelarray_outputs') == False:\n",
    "    os.makedirs(fba_dir+'template/modelarray_outputs')\n",
    "# Make CSVs for each metric containing covariates of interest\n",
    "for metric in ['fd','fdc','log_fc','fa_DKI','md_DKI','kfa_DKI','mk_DKI','ICVF_NODDI','OD_NODDI']:\n",
    "    df_metric = df.copy()\n",
    "    df_metric['scalar_name'] = [metric for ind in range(len(df))]\n",
    "    df_metric['source_file'] = ['fixel_stats/'+metric+'_smooth/'+sub+'_'+metric+'.mif' for sub in df['subject_id']]\n",
    "    df_metric.to_csv(fba_dir+'template/modelarray_inputs/cohort_'+metric+'.csv',index=False)\n",
    "    df_metric_group = df_metric[df['GROUP']!='OTHER']\n",
    "    df_metric_group.to_csv(fba_dir+'template/modelarray_inputs/cohort_'+metric+'_group.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nipype",
   "language": "python",
   "name": "nipype"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
